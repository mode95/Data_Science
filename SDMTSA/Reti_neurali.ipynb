{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reti_neurali.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SZT0anBkMb-8",
        "CvUYIreDMe5b"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "neDQNRH3D0L9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "500adc86-f242-4320-f477-1751da4048a2"
      },
      "source": [
        "# Per sapere che GPU è assegnata \n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 15310953602159984984, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 12437289963953350385\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 13240625933292508450\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 3508088400575831401\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBUsuOo9D6ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "cf91c2b5-8f81-4a06-c488-d19a3e5b2a3b"
      },
      "source": [
        "! pip install pyGPGO"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyGPGO\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/87/a113c91ba014708114f7635d5c0f6a5e5c773480c5f0a537b257a02d180d/pyGPGO-0.4.0.dev1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Building wheels for collected packages: pyGPGO\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.4.0.dev1-cp36-none-any.whl size=19867 sha256=e918fbf74a643461e1db83f99137d667cf1057fdf5c0e07cc320ea69c9f30b06\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/27/04/c4fa3bfe194d36e3cd51542132f43415a6813114a5e8301acb\n",
            "Successfully built pyGPGO\n",
            "Installing collected packages: pyGPGO\n",
            "Successfully installed pyGPGO-0.4.0.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3gIOikYD_hS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "194f9e70-915c-43cc-ef21-bf2b536e82fe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from pyGPGO.surrogates.RandomForest import RandomForest\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "\n",
        "from keras import models, layers, optimizers, metrics, callbacks"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-eY79oEV51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2891089a-908b-43d5-dcf4-cafc318b8519"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AHVenWbiQyYyObuiEGYVhgC_aaTn789vGiMjGRWTl6ogUhurLsMDIs\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj0KKbH8Etry",
        "colab_type": "text"
      },
      "source": [
        "# Carico dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPSmLr9QEsFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/progetto_streaming/time_series_dataset.csv\", sep = \";\")\n",
        "data[\"Data\"] = pd.to_datetime(data[\"Data\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjmrY1qEFDWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bbb9e11a-6da7-4a3a-d0b1-be4ffb3683b5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>41.651044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-02</td>\n",
              "      <td>131.286604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-03</td>\n",
              "      <td>117.388117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>116.461280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>123.823765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Data       value\n",
              "0 2010-01-01   41.651044\n",
              "1 2010-01-02  131.286604\n",
              "2 2010-01-03  117.388117\n",
              "3 2010-01-04  116.461280\n",
              "4 2010-01-05  123.823765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WwMVCPoFeqc",
        "colab_type": "text"
      },
      "source": [
        "# Split train test e standardizzazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMfOJvQ6Fgb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[data[\"Data\"] <= pd.to_datetime(\"2016-12-31\")]\n",
        "test  = data[data[\"Data\"]  > pd.to_datetime(\"2016-12-31\")]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN31J3iNIpjX",
        "colab_type": "text"
      },
      "source": [
        "I dati vengono standardizzati calcolando la \"maschera\" sul train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kvyjKDOF6gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train[\"value\"].mean()\n",
        "std = train[\"value\"].std()\n",
        "\n",
        "train[\"value\"] = (train[\"value\"] - mean)/std\n",
        "test[\"value\"] = (test[\"value\"] - mean)/std\n",
        "\n",
        "stand_data = pd.concat([train, test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSDpeaA78juy",
        "colab_type": "text"
      },
      "source": [
        "Viene creato il dataset per le previsioni con reti neurali che consiste in sequenze di train (2 anni di dati) e test (334 giorni di dati).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7yxNKyJ20B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(X, y, time_steps=1, prev_steps = 1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps - prev_steps + 1):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        V = y.iloc[i + time_steps : i + time_steps + prev_steps].values\n",
        "        ys.append(V)\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQQMtmf_3H2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_step = 730\n",
        "prev_step = 334\n",
        "\n",
        "X, y = create_dataset(stand_data[\"value\"], stand_data[\"value\"], time_step, prev_step)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIdlqiXee3nT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4af4a402-dbd3-4f4b-d395-864f109090de"
      },
      "source": [
        "# calcolo ultimo indice train per splittare i dati in train e test\n",
        "\n",
        "last_index = stand_data.loc[len(train)-1:len(train)-1][\"value\"].values[0]\n",
        "\n",
        "for i in range(len(X)):\n",
        "    if last_index == X[i][-1]:\n",
        "        print(i)\n",
        "        break\n",
        "last_index = i"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3O5YbnKYdGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split e reshape per rete neurale\n",
        "\n",
        "X_train, X_test = X[:last_index], X[last_index:]\n",
        "y_train, y_test = y[:last_index], y[last_index:]\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(-1, X_test.shape[1], 1)\n",
        "\n",
        "y_train = y_train.reshape(-1, y_train.shape[1])\n",
        "y_test = y_test.reshape(-1, y_test.shape[1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2_7hfbqZ3Xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9da5ae0c-e9e8-4b0d-d349-f448578d96aa"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1827, 730, 1), (397, 730, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CP1fCxY9UgL",
        "colab_type": "text"
      },
      "source": [
        "# Modelli di prova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWgWH4RcMLv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mape(actual, pred): \n",
        "    actual, pred = np.array(actual), np.array(pred)\n",
        "    return np.mean(np.abs((actual - pred) / actual)) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ansc7yzy-820",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(network_history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7JLKaO7LoTV",
        "colab_type": "text"
      },
      "source": [
        "Si provano due semplici modelli il primo con un layer LSTM e e il relativo strato di output, il secondo con un layer GRU e lo starto di output.\n",
        "\n",
        "L'ottimizzatore utilizzato è ADAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZT0anBkMb-8",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGVpjOJ7R8gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti5uXGM59Jm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.LSTM(128, input_shape = (X_train.shape[1], X_train.shape[2]), \n",
        "                      return_sequences = False))\n",
        "\n",
        "model.add(layers.Dense(prev_step, activation = \"linear\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbo82Cam9JsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\",\n",
        "            optimizer= optimizers.Adam(), \n",
        "            metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FVjdo109JuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=16,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50c34FgMGnKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_plot = list(range(1,history.epoch[-1]+2))\n",
        "   \n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YHOJT9WJ_Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_mse, test_mae = model.evaluate(X_test, y_test)\n",
        "print(\"TEST MSE:\", test_mse)\n",
        "print(\"TEST MAE:\", test_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaLv63eYKSxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Previsioni sul test e trasformazione inversa alla standardizzazione\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "true_pred = pred*std + mean\n",
        "true_y_test = y_test*std + mean\n",
        "\n",
        "print(\"MAPE on test set: \" + str(mape(true_y_test, true_pred)))\n",
        "print(\"MSE on test set: \" + str(mean_squared_error(true_y_test, true_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUYIreDMe5b",
        "colab_type": "text"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PiMXDGefMgZd",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.GRU(128, input_shape = (X_train.shape[1], X_train.shape[2]), \n",
        "                      return_sequences = False))\n",
        "\n",
        "\n",
        "model.add(layers.Dense(prev_step, activation = \"linear\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9jQoaj3MxMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\",\n",
        "            optimizer= optimizers.Adam(), \n",
        "            metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9ZRtYxM22c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=16,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks = [es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QkJgOp1M4mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_plot = list(range(1,history.epoch[-1]+2))\n",
        "   \n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0oBjfBoM6nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_mse, test_mae = model.evaluate(X_test, y_test)\n",
        "print(\"TEST MSE:\", test_mse)\n",
        "print(\"TEST MAE:\", test_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zypaLGpoM9nC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Previsioni sul test e trasformazione inversa alla standardizzazione\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "true_pred = pred*std + mean\n",
        "true_y_test = y_test*std + mean\n",
        "\n",
        "print(\"MAPE on test set: \" + str(mape(true_y_test, true_pred)))\n",
        "print(\"MSE on test set: \" + str(mean_squared_error(true_y_test, true_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hJEW7lCEub-"
      },
      "source": [
        "# AUTOML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-_CPAmvNjaA",
        "colab_type": "text"
      },
      "source": [
        "Si propone ora una tecnica di ottimizzazione di iperparametri per migliorare i risultati ottenuti. \n",
        "Si utilizza un architettura di soli layers LSTM e Dense dove sia il *numero di strati* che di *neuroni* sono considerati iperparametri da ottimizzare.\n",
        "\n",
        "Inoltre viene ottimizzato anche il *learning rate*  e il *batch size*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLoabK6yO_HH",
        "colab_type": "text"
      },
      "source": [
        "La metrica da minimizzare è il *MSE*, usando la libreria pyGPGO che permette solo massimizzazioni di funzioni black box, la funzione che si utilizzerà come valutazione del modello restituirà l'inverso del *MSE* che alla fine verà nuovamente convertito nella forma corretta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqypyZM5PrgB",
        "colab_type": "text"
      },
      "source": [
        "La funzione di acquisizione utilizzata è *Expected improvement*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwPORDw4E5gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzWz5VvhKRJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(network_history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVfmmI7bEucD",
        "colab": {}
      },
      "source": [
        "def mape(actual, pred): \n",
        "    actual, pred = np.array(actual), np.array(pred)\n",
        "    return np.mean(np.abs((actual - pred) / actual)) * 100"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p32bccVGEucH",
        "colab": {}
      },
      "source": [
        "def resultDataframe(hyperparams, score, initial):\n",
        "  result = pd.DataFrame(hyperparams,columns=['lr', 'n_neuron', 'n_neuron1', 'n_layers_LSTM', 'n_layers_dense', 'n_batch_size'])\n",
        "  result['mse'] = 1/score\n",
        "  result['phase']=\"increment\"\n",
        "  result.loc[0:initial-1,'phase']='initial'\n",
        "  return result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xUE7Wf2Ip9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(n_neuron, n_neuron1, n_layers_LSTM, n_layers_dense): \n",
        "     \n",
        "    model = models.Sequential()\n",
        "\n",
        "    if int(n_layers_LSTM) == 0:\n",
        "        condition = False\n",
        "    else: \n",
        "        condition = True\n",
        "\n",
        "    model.add(layers.LSTM(int(n_neuron), input_shape = (X_train.shape[1], X_train.shape[2]), \n",
        "                      return_sequences = condition))\n",
        "    for i in range(int(n_layers_LSTM)):\n",
        "        if i == int(n_layers_LSTM) -1:\n",
        "            condition = False\n",
        "        model.add(layers.LSTM(int(n_neuron), return_sequences = condition))\n",
        "\n",
        "    for i in range(int(n_layers_dense)):\n",
        "            model.add(layers.Dense(int(n_neuron1), activation=\"relu\"))\n",
        "    \n",
        "    model.add(layers.Dense(prev_step, activation=\"linear\"))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "as66wl6sEucL",
        "colab": {}
      },
      "source": [
        "range_lr = [0.0001, 0.01]\n",
        "range_neuron = [64, 1024]\n",
        "range_neuron1 = [16, 1024]\n",
        "range_layers_LSTM = [0, 3]\n",
        "range_layers_dense = [0,3]\n",
        "range_batch_size = [1, 128]\n",
        "\n",
        "\n",
        "param = {'lr': ('cont', range_lr), \n",
        "         'n_neuron': ('int', range_neuron),\n",
        "         'n_neuron1' : ('int', range_neuron1),\n",
        "         'n_layers_LSTM' : ('int', range_layers_LSTM),\n",
        "         'n_layers_dense' : ('int', range_layers_dense),\n",
        "         'n_batch_size' : ('int', range_batch_size)         \n",
        "         }\n",
        "\n",
        "rf_model = RandomForest()\n",
        "\n",
        "f_acq = Acquisition(mode = \"ExpectedImprovement\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOb6qkgrEucN",
        "colab": {}
      },
      "source": [
        "# Funzione da massimizzare\n",
        "def compute_mse(lr, n_neuron, n_neuron1, n_layers_LSTM, n_layers_dense, n_batch_size):\n",
        "\n",
        "    model = create_model(n_neuron, n_neuron1, n_layers_LSTM, n_layers_dense)\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate = lr),\n",
        "                  loss=\"mse\",\n",
        "                  metrics=[\"mae\"])\n",
        "    \n",
        "    \n",
        "    \n",
        "    model.fit(X_train, y_train, \n",
        "              batch_size = int(n_batch_size),\n",
        "              epochs = 100,\n",
        "              validation_split = 0.2,\n",
        "              callbacks = [es],\n",
        "              verbose = 0)\n",
        "    \n",
        "    score = 1 / model.evaluate(X_test, y_test)[0]\n",
        "\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X0INdpEGEucR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3357e9f9-5fc6-4d02-c91d-0d80994e3d0b"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "SMBO_exp_nn = GPGO(rf_model, f_acq,\n",
        "                   compute_mse,\n",
        "                   param, n_jobs = 1)\n",
        "SMBO_exp_nn.run(init_evals=10,\n",
        "                max_iter=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "13/13 [==============================] - 4s 313ms/step - loss: 0.7203 - mae: 0.6540\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6562 - mae: 0.6465\n",
            "13/13 [==============================] - 4s 328ms/step - loss: 0.7053 - mae: 0.6386\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.6937 - mae: 0.6265\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 0.7565 - mae: 0.6557\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.6675 - mae: 0.6250\n",
            "13/13 [==============================] - 3s 245ms/step - loss: 0.8766 - mae: 0.6767\n",
            "13/13 [==============================] - 2s 170ms/step - loss: 0.7141 - mae: 0.6640\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.6944 - mae: 0.6300\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.6908 - mae: 0.6282\n",
            "init   \t [3.80794718e-03 9.24000000e+02 2.86000000e+02 2.00000000e+00\n",
            " 0.00000000e+00 2.10000000e+01]. \t  1.388249505033405 \t 1.523981853431295\n",
            "init   \t [1.64458454e-03 5.30000000e+02 2.30000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 8.80000000e+01]. \t  1.523981853431295 \t 1.523981853431295\n",
            "init   \t [3.40371525e-03 9.35000000e+02 6.79000000e+02 2.00000000e+00\n",
            " 1.00000000e+00 5.30000000e+01]. \t  1.417931459274147 \t 1.523981853431295\n",
            "init   \t [9.70210754e-03 5.55000000e+02 4.29000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 6.40000000e+01]. \t  1.441451918699275 \t 1.523981853431295\n",
            "init   \t [9.92289444e-03 2.24000000e+02 4.75000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 1.25000000e+02]. \t  1.3218057160487144 \t 1.523981853431295\n",
            "init   \t [4.37625568e-03 6.24000000e+02 4.90000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 4.20000000e+01]. \t  1.4982303124605398 \t 1.523981853431295\n",
            "init   \t [5.61990066e-04 7.63000000e+02 9.91000000e+02 2.00000000e+00\n",
            " 1.00000000e+00 6.20000000e+01]. \t  1.1407480115529762 \t 1.523981853431295\n",
            "init   \t [7.87324202e-03 6.26000000e+02 8.91000000e+02 2.00000000e+00\n",
            " 0.00000000e+00 3.00000000e+00]. \t  1.40037881608122 \t 1.523981853431295\n",
            "init   \t [8.61341003e-03 7.10000000e+02 3.60000000e+01 0.00000000e+00\n",
            " 2.00000000e+00 1.80000000e+01]. \t  1.440154072269275 \t 1.523981853431295\n",
            "init   \t [9.49396682e-03 3.79000000e+02 2.90000000e+01 1.00000000e+00\n",
            " 1.00000000e+00 9.00000000e+00]. \t  1.4475420100583762 \t 1.523981853431295\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.6523 - mae: 0.6266\n",
            "1      \t [1.69199971e-03 4.01000000e+02 7.21000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 8.00000000e+01]. \t  \u001b[92m1.5329959025302375\u001b[0m \t 1.5329959025302375\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6351 - mae: 0.6122\n",
            "2      \t [1.37590925e-03 2.46000000e+02 8.63000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 1.18000000e+02]. \t  \u001b[92m1.5746107353713816\u001b[0m \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.7622 - mae: 0.6464\n",
            "3      \t [5.46496704e-04 4.62000000e+02 8.32000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 1.22000000e+02]. \t  1.3119562112393561 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.7444 - mae: 0.6288\n",
            "4      \t [1.01999853e-03 4.69000000e+02 9.93000000e+02 2.00000000e+00\n",
            " 0.00000000e+00 1.17000000e+02]. \t  1.3433727742993045 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7739 - mae: 0.6512\n",
            "5      \t [1.34991245e-03 1.42000000e+02 7.41000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 1.25000000e+02]. \t  1.2921792468379487 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9724 - mae: 0.7240\n",
            "6      \t [4.0884455e-03 1.7400000e+02 9.4200000e+02 1.0000000e+00 2.0000000e+00\n",
            " 6.7000000e+01]. \t  1.0283364112949442 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.7318 - mae: 0.6425\n",
            "7      \t [7.6141523e-03 1.6500000e+02 7.6800000e+02 0.0000000e+00 2.0000000e+00\n",
            " 8.9000000e+01]. \t  1.366569562765275 \t 1.5746107353713816\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.6511 - mae: 0.6263\n",
            "8      \t [2.24064739e-03 5.28000000e+02 7.66000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 5.70000000e+01]. \t  1.5358067586893898 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 0.9436 - mae: 0.7204\n",
            "9      \t [1.41080567e-03 2.13000000e+02 8.95000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 7.70000000e+01]. \t  1.059810990067519 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 39ms/step - loss: 1.5114 - mae: 0.9440\n",
            "10     \t [2.77913795e-03 1.85000000e+02 3.55000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 8.50000000e+01]. \t  0.6616429720002861 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.9304 - mae: 0.7042\n",
            "11     \t [8.0437207e-03 2.2900000e+02 2.0400000e+02 1.0000000e+00 2.0000000e+00\n",
            " 9.0000000e+01]. \t  1.0748003906055057 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.9894 - mae: 0.7261\n",
            "12     \t [1.89999476e-03 2.55000000e+02 4.02000000e+02 1.00000000e+00\n",
            " 0.00000000e+00 2.30000000e+01]. \t  1.0106657995265347 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.6969 - mae: 0.6348\n",
            "13     \t [7.68583018e-03 4.30000000e+02 1.22000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 9.90000000e+01]. \t  1.434827414985197 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.9181 - mae: 0.7119\n",
            "14     \t [2.24932197e-03 3.65000000e+02 7.41000000e+02 2.00000000e+00\n",
            " 1.00000000e+00 6.90000000e+01]. \t  1.0892140308853158 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6833 - mae: 0.6122\n",
            "15     \t [2.27485312e-03 3.30000000e+02 8.85000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 1.05000000e+02]. \t  1.4635708837849652 \t 1.5746107353713816\n",
            "13/13 [==============================] - 3s 216ms/step - loss: 0.8745 - mae: 0.6750\n",
            "16     \t [1.45137982e-03 7.16000000e+02 9.73000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 1.12000000e+02]. \t  1.1434776403483673 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.8539 - mae: 0.6712\n",
            "17     \t [1.99298413e-03 3.98000000e+02 4.60000000e+01 2.00000000e+00\n",
            " 1.00000000e+00 1.05000000e+02]. \t  1.171048742068894 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.7169 - mae: 0.6228\n",
            "18     \t [1.3733782e-03 6.5100000e+02 6.6400000e+02 0.0000000e+00 2.0000000e+00\n",
            " 9.2000000e+01]. \t  1.3948507498982579 \t 1.5746107353713816\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.6729 - mae: 0.6270\n",
            "19     \t [1.42778426e-03 5.35000000e+02 8.08000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 6.40000000e+01]. \t  1.4860860485625091 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 1.0256 - mae: 0.7560\n",
            "20     \t [2.57368791e-03 3.93000000e+02 6.75000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 8.70000000e+01]. \t  0.9750782574935982 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.6677 - mae: 0.6258\n",
            "21     \t [2.63527542e-03 4.72000000e+02 3.77000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 8.40000000e+01]. \t  1.497572200447686 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.7159 - mae: 0.6280\n",
            "22     \t [8.70607616e-04 4.01000000e+02 3.16000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 6.70000000e+01]. \t  1.3969054658457805 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.9453 - mae: 0.7107\n",
            "23     \t [2.72716036e-03 3.61000000e+02 8.47000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 1.27000000e+02]. \t  1.057847437752719 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0348 - mae: 0.7550\n",
            "24     \t [1.48519787e-03 5.20000000e+02 4.76000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 7.90000000e+01]. \t  0.9664123470620453 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 1.3472 - mae: 0.8927\n",
            "25     \t [2.1025045e-03 4.1300000e+02 7.0300000e+02 1.0000000e+00 2.0000000e+00\n",
            " 1.5000000e+01]. \t  0.7422680485348657 \t 1.5746107353713816\n",
            "13/13 [==============================] - 3s 233ms/step - loss: 0.6772 - mae: 0.6289\n",
            "26     \t [2.81133102e-03 7.54000000e+02 1.06000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 9.10000000e+01]. \t  1.4765835972570416 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 0.6729 - mae: 0.6260\n",
            "27     \t [5.74682239e-03 4.41000000e+02 4.61000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 4.80000000e+01]. \t  1.4860607752678454 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 40ms/step - loss: 0.6469 - mae: 0.6316\n",
            "28     \t [2.79805857e-03 5.85000000e+02 5.93000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 3.80000000e+01]. \t  1.5457926777525826 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.8896 - mae: 0.6919\n",
            "29     \t [2.59923044e-03 5.28000000e+02 5.95000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 2.20000000e+01]. \t  1.124078979987002 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 1.0938 - mae: 0.7763\n",
            "30     \t [3.4568608e-03 4.2100000e+02 7.9800000e+02 2.0000000e+00 2.0000000e+00\n",
            " 9.4000000e+01]. \t  0.9142168618500259 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6900 - mae: 0.6307\n",
            "31     \t [2.15001454e-03 5.68000000e+02 2.13000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 8.50000000e+01]. \t  1.4493274497115247 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6852 - mae: 0.6206\n",
            "32     \t [2.60305445e-03 5.31000000e+02 5.84000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 1.12000000e+02]. \t  1.4594896575650038 \t 1.5746107353713816\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.6782 - mae: 0.6268\n",
            "33     \t [4.5825877e-03 4.9400000e+02 5.1000000e+02 2.0000000e+00 2.0000000e+00\n",
            " 9.0000000e+01]. \t  1.4745919830936958 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 0.6739 - mae: 0.6249\n",
            "34     \t [4.8739411e-03 4.3900000e+02 3.6100000e+02 1.0000000e+00 0.0000000e+00\n",
            " 6.9000000e+01]. \t  1.4837973047717747 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 34ms/step - loss: 0.9068 - mae: 0.6972\n",
            "35     \t [3.81512816e-03 4.90000000e+02 4.10000000e+02 0.00000000e+00\n",
            " 1.00000000e+00 4.60000000e+01]. \t  1.1028236180668014 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.7265 - mae: 0.6136\n",
            "36     \t [3.15776549e-03 4.82000000e+02 3.62000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 7.40000000e+01]. \t  1.3764331781348402 \t 1.5746107353713816\n",
            "13/13 [==============================] - 4s 321ms/step - loss: 0.8102 - mae: 0.6658\n",
            "37     \t [1.6695612e-03 8.6700000e+02 2.4900000e+02 2.0000000e+00 2.0000000e+00\n",
            " 3.6000000e+01]. \t  1.234287426137379 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.6699 - mae: 0.6281\n",
            "38     \t [7.70815106e-03 4.53000000e+02 7.13000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 6.70000000e+01]. \t  1.4926651537059648 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 0.6717 - mae: 0.6384\n",
            "39     \t [6.22991941e-03 6.20000000e+02 7.26000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 5.20000000e+01]. \t  1.4887045101123146 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6829 - mae: 0.6352\n",
            "40     \t [6.17291999e-03 5.10000000e+02 6.25000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 6.00000000e+00]. \t  1.4644456005223299 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 0.6545 - mae: 0.6136\n",
            "41     \t [2.71096845e-03 5.52000000e+02 8.14000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 5.00000000e+01]. \t  1.5278403125543838 \t 1.5746107353713816\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.6873 - mae: 0.6353\n",
            "42     \t [7.48112272e-03 4.81000000e+02 6.77000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 6.00000000e+00]. \t  1.4549352255601866 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.8822 - mae: 0.6789\n",
            "43     \t [1.22624104e-03 4.06000000e+02 4.45000000e+02 2.00000000e+00\n",
            " 0.00000000e+00 8.20000000e+01]. \t  1.1335004003717526 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 1.1516 - mae: 0.8086\n",
            "44     \t [6.9619198e-03 4.4500000e+02 7.9100000e+02 0.0000000e+00 2.0000000e+00\n",
            " 3.4000000e+01]. \t  0.8683532007696605 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.7043 - mae: 0.6402\n",
            "45     \t [8.93586373e-03 3.88000000e+02 4.90000000e+01 2.00000000e+00\n",
            " 2.00000000e+00 1.90000000e+01]. \t  1.419905040153673 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.6736 - mae: 0.6336\n",
            "46     \t [8.5230454e-03 5.8800000e+02 8.4600000e+02 1.0000000e+00 2.0000000e+00\n",
            " 3.6000000e+01]. \t  1.48457970971916 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 0.6982 - mae: 0.6438\n",
            "47     \t [8.74607895e-03 5.34000000e+02 7.05000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 1.00000000e+00]. \t  1.4322793377434595 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.8377 - mae: 0.6746\n",
            "48     \t [1.25358807e-03 2.72000000e+02 9.70000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 1.08000000e+02]. \t  1.1936920197553949 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.6905 - mae: 0.6408\n",
            "49     \t [5.42113271e-03 6.34000000e+02 7.85000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 1.15000000e+02]. \t  1.4482460064981617 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.6829 - mae: 0.6287\n",
            "50     \t [3.01567133e-03 4.62000000e+02 6.83000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 4.00000000e+00]. \t  1.4643021913540863 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.6654 - mae: 0.6273\n",
            "51     \t [3.32358362e-03 6.36000000e+02 8.74000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 1.30000000e+01]. \t  1.502779304244623 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6873 - mae: 0.6282\n",
            "52     \t [8.82541688e-03 3.86000000e+02 1.96000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 6.60000000e+01]. \t  1.4550026052163996 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.8367 - mae: 0.6792\n",
            "53     \t [2.59526391e-03 6.32000000e+02 8.78000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 7.90000000e+01]. \t  1.1951651749437278 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.6782 - mae: 0.6288\n",
            "54     \t [4.43083645e-03 4.62000000e+02 8.31000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 1.01000000e+02]. \t  1.4745753937607025 \t 1.5746107353713816\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.6774 - mae: 0.6137\n",
            "55     \t [1.87782973e-03 5.22000000e+02 7.98000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 8.30000000e+01]. \t  1.476146554821065 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.6662 - mae: 0.6372\n",
            "56     \t [9.69450204e-03 4.22000000e+02 1.41000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 4.10000000e+01]. \t  1.5010570877487512 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 63ms/step - loss: 0.8716 - mae: 0.6967\n",
            "57     \t [7.28663213e-03 4.25000000e+02 8.10000000e+01 1.00000000e+00\n",
            " 0.00000000e+00 4.80000000e+01]. \t  1.1472971164487136 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 0.6834 - mae: 0.6256\n",
            "58     \t [5.65298453e-03 4.48000000e+02 5.27000000e+02 2.00000000e+00\n",
            " 1.00000000e+00 5.90000000e+01]. \t  1.4631991871007095 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6690 - mae: 0.6066\n",
            "59     \t [1.56164024e-03 3.90000000e+02 8.51000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 9.70000000e+01]. \t  1.4947695766231277 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.8980 - mae: 0.7068\n",
            "60     \t [1.77279563e-03 4.04000000e+02 6.35000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 5.20000000e+01]. \t  1.113567856806721 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.6762 - mae: 0.6294\n",
            "61     \t [9.07435274e-03 4.20000000e+02 5.10000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 7.20000000e+01]. \t  1.4787504089714227 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.7773 - mae: 0.6576\n",
            "62     \t [9.05803581e-03 4.53000000e+02 7.75000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 4.50000000e+01]. \t  1.2865845779474865 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.6532 - mae: 0.6106\n",
            "63     \t [2.77250139e-03 7.56000000e+02 3.37000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 7.70000000e+01]. \t  1.5310159748513992 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6896 - mae: 0.6174\n",
            "64     \t [2.77162961e-03 5.52000000e+02 3.67000000e+02 1.00000000e+00\n",
            " 1.00000000e+00 1.04000000e+02]. \t  1.450096601275588 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 36ms/step - loss: 0.9823 - mae: 0.7425\n",
            "65     \t [1.95803828e-03 5.34000000e+02 7.69000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 1.50000000e+01]. \t  1.0179837434148489 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.6524 - mae: 0.6226\n",
            "66     \t [3.49095606e-03 4.67000000e+02 7.67000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 7.90000000e+01]. \t  1.5327544504533477 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.6784 - mae: 0.6290\n",
            "67     \t [5.08094142e-03 4.51000000e+02 8.27000000e+02 1.00000000e+00\n",
            " 2.00000000e+00 1.50000000e+01]. \t  1.4740552224567318 \t 1.5746107353713816\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 1.0776 - mae: 0.7695\n",
            "68     \t [8.95895102e-03 1.74000000e+02 2.42000000e+02 2.00000000e+00\n",
            " 2.00000000e+00 7.00000000e+00]. \t  0.9279814470261999 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 0.7398 - mae: 0.6340\n",
            "69     \t [2.21860893e-03 6.08000000e+02 7.40000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 5.40000000e+01]. \t  1.3516325443661608 \t 1.5746107353713816\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.6923 - mae: 0.6275\n",
            "70     \t [6.69539395e-03 7.41000000e+02 7.58000000e+02 0.00000000e+00\n",
            " 2.00000000e+00 8.40000000e+01]. \t  1.4444603244737693 \t 1.5746107353713816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TU9xBt6AEucT",
        "colab": {}
      },
      "source": [
        "result = resultDataframe(SMBO_exp_nn.GP.X, SMBO_exp_nn.GP.y, initial=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iSC7mAhTLa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "53002439-7a94-4de1-dde5-299245732392"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lr</th>\n",
              "      <th>n_neuron</th>\n",
              "      <th>n_neuron1</th>\n",
              "      <th>n_layers_LSTM</th>\n",
              "      <th>n_layers_dense</th>\n",
              "      <th>n_batch_size</th>\n",
              "      <th>mse</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003808</td>\n",
              "      <td>924.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.720332</td>\n",
              "      <td>initial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001645</td>\n",
              "      <td>530.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.656176</td>\n",
              "      <td>initial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003404</td>\n",
              "      <td>935.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.705253</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.009702</td>\n",
              "      <td>555.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.693745</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.009923</td>\n",
              "      <td>224.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.756541</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.003491</td>\n",
              "      <td>467.0</td>\n",
              "      <td>767.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.652420</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0.005081</td>\n",
              "      <td>451.0</td>\n",
              "      <td>827.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.678401</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.008959</td>\n",
              "      <td>174.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.077608</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.002219</td>\n",
              "      <td>608.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.739846</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>0.006695</td>\n",
              "      <td>741.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.692300</td>\n",
              "      <td>increment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          lr  n_neuron  n_neuron1  ...  n_batch_size       mse      phase\n",
              "0   0.003808     924.0      286.0  ...          21.0  0.720332    initial\n",
              "1   0.001645     530.0      230.0  ...          88.0  0.656176    initial\n",
              "2   0.003404     935.0      679.0  ...          53.0  0.705253  increment\n",
              "3   0.009702     555.0      429.0  ...          64.0  0.693745  increment\n",
              "4   0.009923     224.0      475.0  ...         125.0  0.756541  increment\n",
              "..       ...       ...        ...  ...           ...       ...        ...\n",
              "75  0.003491     467.0      767.0  ...          79.0  0.652420  increment\n",
              "76  0.005081     451.0      827.0  ...          15.0  0.678401  increment\n",
              "77  0.008959     174.0      242.0  ...           7.0  1.077608  increment\n",
              "78  0.002219     608.0      740.0  ...          54.0  0.739846  increment\n",
              "79  0.006695     741.0      758.0  ...          84.0  0.692300  increment\n",
              "\n",
              "[80 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X6kDoWsdEucV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4f82b26a-accb-4b90-de63-c1d0bf351c88"
      },
      "source": [
        "ndcg_exp_nn = np.minimum.accumulate(result[\"mse\"])\n",
        "\n",
        "\n",
        "#plt.figure(figsize=(10,8))\n",
        "plt.plot(ndcg_exp_nn,marker='o',color='blue',label=\"ExpectedImprovement\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.xlabel(\"Iterazioni\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IrPib7wdEucX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba45fcd3-8600-44e5-ddc4-7310336dcc88"
      },
      "source": [
        "print(\"MSE modello migliore test: \" + str(1/SMBO_exp_nn.getResult()[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE modello migliore test: 0.6350775957107544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wiBdOeOiEucZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "064aaf31-5ec3-4296-87d6-68edf257ba6d"
      },
      "source": [
        "# Parametri modello migliore\n",
        "\n",
        "SMBO_exp_nn.getResult()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('lr', 0.0013759092469154276),\n",
              "             ('n_neuron', 246.0),\n",
              "             ('n_neuron1', 863.0),\n",
              "             ('n_layers_LSTM', 2.0),\n",
              "             ('n_layers_dense', 2.0),\n",
              "             ('n_batch_size', 118.0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd-uq3C2zLvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape(-1,730,1)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VQ95jg7QEucb",
        "colab": {}
      },
      "source": [
        "#np.random.seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "\n",
        "best_mod = create_model(246, 863, 2, 2)\n",
        "\n",
        "best_mod.compile(loss=\"mse\",\n",
        "            optimizer= optimizers.Adam(lr = 0.0013759092469154276), \n",
        "            metrics=['mae'])\n",
        "\n",
        "history = best_mod.fit(X_train, y_train,\n",
        "                    batch_size=118,\n",
        "                    epochs=100,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    callbacks = [es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2lfe4PCxEuce",
        "colab": {}
      },
      "source": [
        "x_plot = list(range(1,history.epoch[-1]+2))\n",
        " \n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvtad_QiEucg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6da71034-56e6-415f-db6f-bf6a206f10eb"
      },
      "source": [
        "test_mse, test_mae = best_mod.evaluate(X_test, y_test)\n",
        "print(\"TEST MSE:\", test_mse)\n",
        "print(\"TEST MAE:\", test_mae)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 1s 63ms/step - loss: 0.7029 - mae: 0.6146\n",
            "TEST MSE: 0.7028965950012207\n",
            "TEST MAE: 0.6146093606948853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFUceg0SPMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "58a7458a-fa2d-435c-9dd1-acc5a6c7f6f3"
      },
      "source": [
        "# Previsioni e trasformzione inversa alla standardizzazione\n",
        "\n",
        "pred_train = best_mod.predict(X_train)*std + mean\n",
        "pred_test = best_mod.predict(X_test)*std + mean\n",
        "\n",
        "\n",
        "print(\"MAPE on train set: \" + str(mape(y_train*std + mean, pred_train)))\n",
        "print(\"MAPE on test set: \"+ str(mape(y_test*std + mean, pred_test)))\n",
        "\n",
        "\n",
        "print(\"MSE on train set: \"+ str(mean_squared_error(y_train*std + mean, pred_train)))\n",
        "print(\"MSE on test set: \" + str(mean_squared_error(y_test*std + mean, pred_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE on train set: 20.418118234420145\n",
            "MAPE on test set: 18.32667782698704\n",
            "MSE on train set: 572.5470019276233\n",
            "MSE on test set: 815.4316568336255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsxb4d9SVFj8",
        "colab_type": "text"
      },
      "source": [
        "# Previsioni e grafici finali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veKxqlIE6AjP",
        "colab_type": "text"
      },
      "source": [
        "Per le previsioni finali della rete neurale si allena il modello migliore ottenuto per altre 25 epoche sul test set, in quanto precedentemente non era stato usato e anche per conferirgli più importanza essendo i dati più recenti disponibili."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3n24LNVzBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_final = data[data[\"Data\"] >= pd.to_datetime(\"2017-01-01\")]\n",
        "X_final = (X_final[\"value\"] - mean)/std\n",
        "X_final = X_final.values.reshape(1,-1,1)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szmrf0U-anx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_mod.fit(X_test, y_test, \n",
        "             epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJvi7QEKVe3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_ML = best_mod.predict(X_final)[0] * std + mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YeCQncpk8G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prova = pd.read_csv('/content/drive/My Drive/progetto_streaming/SDMTSA_790032_0.csv', header=0, index_col=0, parse_dates=True, squeeze=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjSM0wS3lGlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prova[\"ML\"] = pred_ML"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umIIk7CNlI0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prova.plot(figsize=(10,7))\n",
        "plt.ylabel(\"Value\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKQ0c5Usbjr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.read_csv(\"/content/drive/My Drive/progetto_streaming/SDMTSA_790032_0.csv\")"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgz8uYYdb01L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final[\"ML\"] = pred_ML"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0eOyKRcDmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.to_csv(\"/content/drive/My Drive/progetto_streaming/SDMTSA_790032_0.csv\", index=False)"
      ],
      "execution_count": 265,
      "outputs": []
    }
  ]
}